{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-08 13:15:52.624494: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 13:15:52.637919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741439752.653187 1064036 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741439752.657567 1064036 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 13:15:52.675764: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, XLNetModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000005</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Three men hammer on an anvil and pass a bottle...</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000004</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Lost 1892 French short animated film directed ...</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Lost short film consisting of 300 painted imag...</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000003</td>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Performing on what looks like a small wooden s...</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>390752</td>\n",
       "      <td>tt0407808</td>\n",
       "      <td>Frog and Toad Are Friends</td>\n",
       "      <td>Claymation version of Arnold Lobel's story of ...</td>\n",
       "      <td>Animation,Comedy,Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>390753</td>\n",
       "      <td>tt0407810</td>\n",
       "      <td>From Ardoyne to the √Åras: Inside the McAleese ...</td>\n",
       "      <td>Documentary on the private and public life of ...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>390754</td>\n",
       "      <td>tt0407811</td>\n",
       "      <td>Frontstadt</td>\n",
       "      <td>A young filmmaker tries to gain a very persona...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>390755</td>\n",
       "      <td>tt0407815</td>\n",
       "      <td>Possible Changes</td>\n",
       "      <td>Two friends, Moon-ho and Jong-kyu, in their mi...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>390756</td>\n",
       "      <td>tt0407814</td>\n",
       "      <td>Full Grown Men</td>\n",
       "      <td>A man stuck in the reveries of his youth track...</td>\n",
       "      <td>Comedy,Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         id  \\\n",
       "0                0  tt0000005   \n",
       "1                1  tt0000004   \n",
       "2                2  tt0000002   \n",
       "3                3  tt0000003   \n",
       "4                4  tt0000001   \n",
       "...            ...        ...   \n",
       "207356      390752  tt0407808   \n",
       "207357      390753  tt0407810   \n",
       "207358      390754  tt0407811   \n",
       "207359      390755  tt0407815   \n",
       "207360      390756  tt0407814   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                        Blacksmith Scene   \n",
       "1                                             Un bon bock   \n",
       "2                                  Le clown et ses chiens   \n",
       "3                                            Poor Pierrot   \n",
       "4                                              Carmencita   \n",
       "...                                                   ...   \n",
       "207356                          Frog and Toad Are Friends   \n",
       "207357  From Ardoyne to the √Åras: Inside the McAleese ...   \n",
       "207358                                         Frontstadt   \n",
       "207359                                   Possible Changes   \n",
       "207360                                     Full Grown Men   \n",
       "\n",
       "                                                     desc  \\\n",
       "0       Three men hammer on an anvil and pass a bottle...   \n",
       "1       Lost 1892 French short animated film directed ...   \n",
       "2       Lost short film consisting of 300 painted imag...   \n",
       "3       One night, Arlequin come to see his lover Colo...   \n",
       "4       Performing on what looks like a small wooden s...   \n",
       "...                                                   ...   \n",
       "207356  Claymation version of Arnold Lobel's story of ...   \n",
       "207357  Documentary on the private and public life of ...   \n",
       "207358  A young filmmaker tries to gain a very persona...   \n",
       "207359  Two friends, Moon-ho and Jong-kyu, in their mi...   \n",
       "207360  A man stuck in the reveries of his youth track...   \n",
       "\n",
       "                           genre  \n",
       "0                          Short  \n",
       "1                Animation,Short  \n",
       "2                Animation,Short  \n",
       "3       Animation,Comedy,Romance  \n",
       "4              Documentary,Short  \n",
       "...                          ...  \n",
       "207356   Animation,Comedy,Family  \n",
       "207357               Documentary  \n",
       "207358                     Drama  \n",
       "207359                     Drama  \n",
       "207360              Comedy,Drama  \n",
       "\n",
       "[207361 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('cleaned_imdb_genre.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primaryTitleÍ≥º descriptionÏùÑ ÌïòÎÇòÏùò ÌÖçÏä§Ìä∏Î°ú Ìï©ÏπòÍ∏∞\n",
    "df['text'] = df['title'].astype(str) + \" \" + df['desc'].astype(str)\n",
    "\n",
    "# genre Ïª¨Îüº Ï†ÑÏ≤òÎ¶¨: ÏâºÌëúÎ°ú Íµ¨Î∂ÑÎêú Î¨∏ÏûêÏó¥ÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "def process_genres(genres_str):\n",
    "    if pd.isna(genres_str):\n",
    "        return []\n",
    "    return [g.strip() for g in genres_str.split(',') if g.strip() != \"\"]\n",
    "\n",
    "df['genre_list'] = df['genre'].apply(process_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÑÏ≤¥ Ïû•Î•¥: ['Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "all_genres = set()\n",
    "for genres in df['genre_list']:\n",
    "    for genre in genres:\n",
    "        all_genres.add(genre)\n",
    "all_genres = sorted(list(all_genres))\n",
    "genre2id = {genre: idx for idx, genre in enumerate(all_genres)}\n",
    "num_labels = len(all_genres)\n",
    "print(\"Ï†ÑÏ≤¥ Ïû•Î•¥:\", all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í∞Å ÏÉòÌîåÏóê ÎåÄÌï¥ Î©ÄÌã∞Ìï´ Ïù∏ÏΩîÎî©Îêú Î†àÏù¥Î∏î ÏÉùÏÑ±\n",
    "def encode_labels(genres):\n",
    "    label = [0] * num_labels\n",
    "    for g in genres:\n",
    "        if g in genre2id:\n",
    "            label[genre2id[g]] = 1\n",
    "    return label\n",
    "\n",
    "df['labels'] = df['genre_list'].apply(encode_labels)\n",
    "\n",
    "# Î™®Îç∏ ÌïôÏäµÏóê ÌïÑÏöîÌïú Ïó¥Îßå ÏÑ†ÌÉù\n",
    "df_model = df[['text', 'genre_list', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blacksmith Scene Three men hammer on an anvil ...</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un bon bock Lost 1892 French short animated fi...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le clown et ses chiens Lost short film consist...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor Pierrot One night, Arlequin come to see h...</td>\n",
       "      <td>[Animation, Comedy, Romance]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carmencita Performing on what looks like a sma...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>Frog and Toad Are Friends Claymation version o...</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>From Ardoyne to the √Åras: Inside the McAleese ...</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>Frontstadt A young filmmaker tries to gain a v...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>Possible Changes Two friends, Moon-ho and Jong...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>Full Grown Men A man stuck in the reveries of ...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Blacksmith Scene Three men hammer on an anvil ...   \n",
       "1       Un bon bock Lost 1892 French short animated fi...   \n",
       "2       Le clown et ses chiens Lost short film consist...   \n",
       "3       Poor Pierrot One night, Arlequin come to see h...   \n",
       "4       Carmencita Performing on what looks like a sma...   \n",
       "...                                                   ...   \n",
       "207356  Frog and Toad Are Friends Claymation version o...   \n",
       "207357  From Ardoyne to the √Åras: Inside the McAleese ...   \n",
       "207358  Frontstadt A young filmmaker tries to gain a v...   \n",
       "207359  Possible Changes Two friends, Moon-ho and Jong...   \n",
       "207360  Full Grown Men A man stuck in the reveries of ...   \n",
       "\n",
       "                          genre_list  \\\n",
       "0                            [Short]   \n",
       "1                 [Animation, Short]   \n",
       "2                 [Animation, Short]   \n",
       "3       [Animation, Comedy, Romance]   \n",
       "4               [Documentary, Short]   \n",
       "...                              ...   \n",
       "207356   [Animation, Comedy, Family]   \n",
       "207357                 [Documentary]   \n",
       "207358                       [Drama]   \n",
       "207359                       [Drama]   \n",
       "207360               [Comedy, Drama]   \n",
       "\n",
       "                                                   labels  \n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "207356  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "207357  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "207358  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "207359  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "207360  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[207361 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_descriptions = {\n",
    "    \"Action\": \"This movie has thrilling action sequences with intense fight scenes.\",\n",
    "    \"Adult\": \"This film is intended for mature audiences, featuring explicit themes.\",\n",
    "    \"Adventure\": \"This movie takes the audience on an exciting journey full of discovery.\",\n",
    "    \"Animation\": \"This film is beautifully animated with vibrant characters and stunning visuals.\",\n",
    "    \"Biography\": \"This movie tells the true story of a remarkable person's life.\",\n",
    "    \"Comedy\": \"This movie is full of humor and laughter, guaranteed to entertain.\",\n",
    "    \"Crime\": \"This film revolves around criminal activities, investigations, and justice.\",\n",
    "    \"Documentary\": \"This is a factual film that explores real-life events and issues.\",\n",
    "    \"Drama\": \"This movie tells an emotional and heartfelt story with deep character development.\",\n",
    "    \"Family\": \"This movie is suitable for all ages, bringing warmth and joy to families.\",\n",
    "    \"Fantasy\": \"This film takes place in a magical world with fantastical elements and creatures.\",\n",
    "    \"Film-Noir\": \"This movie features a dark and mysterious atmosphere with complex characters.\",\n",
    "    \"Game-Show\": \"This show features competitive games and exciting challenges.\",\n",
    "    \"History\": \"This film brings historical events and figures to life with great detail.\",\n",
    "    \"Horror\": \"This movie contains scary and suspenseful moments that will keep you on edge.\",\n",
    "    \"Music\": \"This film revolves around music, featuring incredible performances and soundtracks.\",\n",
    "    \"Musical\": \"This movie is filled with songs and dance performances that tell a story.\",\n",
    "    \"Mystery\": \"This film keeps the audience guessing with twists and hidden secrets.\",\n",
    "    \"News\": \"This program covers current events and breaking news from around the world.\",\n",
    "    \"Reality-TV\": \"This show follows real people and their lives, providing entertainment and drama.\",\n",
    "    \"Romance\": \"A heartwarming romantic story unfolds in this film, full of love and emotions.\",\n",
    "    \"Sci-Fi\": \"This movie explores futuristic worlds, advanced technology, and space travel.\",\n",
    "    \"Short\": \"This is a short film that tells a compelling story in a brief runtime.\",\n",
    "    \"Sport\": \"This film is centered around sports, athletes, and competitive events.\",\n",
    "    \"Talk-Show\": \"This show features discussions, interviews, and engaging conversations.\",\n",
    "    \"Thriller\": \"This movie is filled with suspense, unexpected twists, and tension.\",\n",
    "    \"War\": \"This film portrays intense battles and the impact of war on people.\",\n",
    "    \"Western\": \"This movie is set in the Old West, featuring cowboys, duels, and frontier life.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_negatives = {\n",
    "    \"Action\": [\"Adventure\", \"Thriller\"],\n",
    "    \"Adult\": [\"Drama\", \"Romance\"],\n",
    "    \"Adventure\": [\"Fantasy\", \"Action\"],\n",
    "    \"Animation\": [\"Family\", \"Fantasy\"],\n",
    "    \"Biography\": [\"History\", \"Drama\"],\n",
    "    \"Comedy\": [\"Family\", \"Musical\"],\n",
    "    \"Crime\": [\"Thriller\", \"Drama\"],\n",
    "    \"Documentary\": [\"History\", \"News\"],\n",
    "    \"Drama\": [\"Romance\", \"Biography\"],\n",
    "    \"Family\": [\"Animation\", \"Comedy\"],\n",
    "    \"Fantasy\": [\"Sci-Fi\", \"Adventure\"],\n",
    "    \"Film-Noir\": [\"Mystery\", \"Thriller\"],\n",
    "    \"Game-Show\": [\"Reality-TV\", \"Talk-Show\"],\n",
    "    \"History\": [\"Biography\", \"Documentary\"],\n",
    "    \"Horror\": [\"Thriller\", \"Mystery\"],\n",
    "    \"Music\": [\"Musical\", \"Drama\"],\n",
    "    \"Musical\": [\"Music\", \"Comedy\"],\n",
    "    \"Mystery\": [\"Thriller\", \"Crime\"],\n",
    "    \"News\": [\"Documentary\", \"Talk-Show\"],\n",
    "    \"Reality-TV\": [\"Game-Show\", \"Talk-Show\"],\n",
    "    \"Romance\": [\"Drama\", \"Comedy\"],\n",
    "    \"Sci-Fi\": [\"Fantasy\", \"Action\"],\n",
    "    \"Short\": [\"Documentary\", \"Animation\"],\n",
    "    \"Sport\": [\"Drama\", \"Action\"],\n",
    "    \"Talk-Show\": [\"Reality-TV\", \"News\"],\n",
    "    \"Thriller\": [\"Horror\", \"Mystery\"],\n",
    "    \"War\": [\"History\", \"Drama\"],\n",
    "    \"Western\": [\"Adventure\", \"Action\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Three men hammer on an anvil and pass a bottle...</td>\n",
       "      <td>[Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Lost 1892 French short animated film directed ...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Lost short film consisting of 300 painted imag...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "      <td>[Animation, Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Performing on what looks like a small wooden s...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>Frog and Toad Are Friends</td>\n",
       "      <td>Claymation version of Arnold Lobel's story of ...</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>From Ardoyne to the √Åras: Inside the McAleese ...</td>\n",
       "      <td>Documentary on the private and public life of ...</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>Frontstadt</td>\n",
       "      <td>A young filmmaker tries to gain a very persona...</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>Possible Changes</td>\n",
       "      <td>Two friends, Moon-ho and Jong-kyu, in their mi...</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>Full Grown Men</td>\n",
       "      <td>A man stuck in the reveries of his youth track...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0                                        Blacksmith Scene   \n",
       "1                                             Un bon bock   \n",
       "2                                  Le clown et ses chiens   \n",
       "3                                            Poor Pierrot   \n",
       "4                                              Carmencita   \n",
       "...                                                   ...   \n",
       "207356                          Frog and Toad Are Friends   \n",
       "207357  From Ardoyne to the √Åras: Inside the McAleese ...   \n",
       "207358                                         Frontstadt   \n",
       "207359                                   Possible Changes   \n",
       "207360                                     Full Grown Men   \n",
       "\n",
       "                                                     desc  \\\n",
       "0       Three men hammer on an anvil and pass a bottle...   \n",
       "1       Lost 1892 French short animated film directed ...   \n",
       "2       Lost short film consisting of 300 painted imag...   \n",
       "3       One night, Arlequin come to see his lover Colo...   \n",
       "4       Performing on what looks like a small wooden s...   \n",
       "...                                                   ...   \n",
       "207356  Claymation version of Arnold Lobel's story of ...   \n",
       "207357  Documentary on the private and public life of ...   \n",
       "207358  A young filmmaker tries to gain a very persona...   \n",
       "207359  Two friends, Moon-ho and Jong-kyu, in their mi...   \n",
       "207360  A man stuck in the reveries of his youth track...   \n",
       "\n",
       "                          genre_list  \n",
       "0                            [Short]  \n",
       "1                 [Animation, Short]  \n",
       "2                 [Animation, Short]  \n",
       "3       [Animation, Comedy, Romance]  \n",
       "4               [Documentary, Short]  \n",
       "...                              ...  \n",
       "207356   [Animation, Comedy, Family]  \n",
       "207357                 [Documentary]  \n",
       "207358                       [Drama]  \n",
       "207359                       [Drama]  \n",
       "207360               [Comedy, Drama]  \n",
       "\n",
       "[207361 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = df[['title', 'desc', 'genre_list']]\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_counts = Counter(genre for genres in model_df[\"genre_list\"] for genre in genres)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏúºÎ°ú Î≥ÄÌôò\n",
    "genre_count_df = pd.DataFrame(genre_counts.items(), columns=[\"Genre\", \"Count\"]).sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>90068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>62317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Short</td>\n",
       "      <td>43939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romance</td>\n",
       "      <td>21667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>19763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Crime</td>\n",
       "      <td>19038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Action</td>\n",
       "      <td>18591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>14007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Family</td>\n",
       "      <td>12849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animation</td>\n",
       "      <td>12148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>10188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Horror</td>\n",
       "      <td>8093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Western</td>\n",
       "      <td>7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Music</td>\n",
       "      <td>6042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>War</td>\n",
       "      <td>5071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Musical</td>\n",
       "      <td>5041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adult</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>History</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Biography</td>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sport</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Game-Show</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>News</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre  Count\n",
       "7         Drama  90068\n",
       "2        Comedy  62317\n",
       "0         Short  43939\n",
       "3       Romance  21667\n",
       "4   Documentary  19763\n",
       "12        Crime  19038\n",
       "17       Action  18591\n",
       "16    Adventure  14007\n",
       "15       Family  12849\n",
       "1     Animation  12148\n",
       "21     Thriller  10188\n",
       "8        Horror   8093\n",
       "13      Western   7813\n",
       "19      Mystery   6964\n",
       "9       Fantasy   6633\n",
       "11        Music   6042\n",
       "14          War   5071\n",
       "22      Musical   5041\n",
       "20       Sci-Fi   4666\n",
       "27        Adult   4470\n",
       "18      History   4335\n",
       "10    Biography   3662\n",
       "5         Sport   2585\n",
       "25    Game-Show    920\n",
       "23    Film-Noir    868\n",
       "24    Talk-Show    630\n",
       "6          News    611\n",
       "26   Reality-TV    451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064036/555546763.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has_rare\"] = df[\"genre_list\"].apply(lambda x: any(g in rare_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def final_balanced_under_sample(df, genre_counts):\n",
    "    \"\"\"\n",
    "    - Ìù¨Í∑Ä Ïû•Î•¥Îäî Î≥¥Ìò∏\n",
    "    - ÎπàÎèÑ ÎÜíÏùÄ Ïû•Î•¥ (Drama, Comedy, Short) Í∞ïÎ†• Ïñ∏ÎçîÏÉòÌîåÎßÅ\n",
    "    - ÌäπÏ†ï Í∞úÏàò Í∏∞Ï§ÄÏúºÎ°ú ÌôïÏã§ÌïòÍ≤å Ï§ÑÏù¥Í∏∞\n",
    "    \"\"\"\n",
    "    sampled_df = pd.DataFrame()  # ÏµúÏ¢Ö ÏÉòÌîåÎßÅÎêú Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•\n",
    "    processed_titles = set()  # Ï§ëÎ≥µ Î∞©ÏßÄÎ•º ÏúÑÌïú ÏòÅÌôî Ï†úÎ™© Ï†ÄÏû•\n",
    "\n",
    "    # ‚úÖ Ìù¨Í∑Ä Ïû•Î•¥ Í∏∞Ï§Ä (5000Í∞ú Ïù¥Ìïò)\n",
    "    rare_genres = set([genre for genre, count in genre_counts.items() if count <= 5000])\n",
    "\n",
    "    # ‚úÖ ÎπàÎèÑ ÎÜíÏùÄ Ïû•Î•¥ Í∏∞Ï§Ä (15000Í∞ú Ïù¥ÏÉÅ)\n",
    "    high_freq_genres = set([genre for genre, count in genre_counts.items() if count >= 15000])\n",
    "\n",
    "    # üéØ 1. Ìù¨Í∑Ä Ïû•Î•¥ Ìè¨Ìï®Îêú ÏòÅÌôîÎäî Î¨¥Ï°∞Í±¥ Ïú†ÏßÄ\n",
    "    df[\"has_rare\"] = df[\"genre_list\"].apply(lambda x: any(g in rare_genres for g in x))\n",
    "    rare_movies = df[df[\"has_rare\"]]\n",
    "\n",
    "    # üéØ 2. Ìù¨Í∑Ä Ïû•Î•¥Í∞Ä ÏóÜÎäî ÏòÅÌôîÎßå Îî∞Î°ú Î∂ÑÎ¶¨\n",
    "    non_rare_movies = df[~df[\"has_rare\"]]\n",
    "\n",
    "    # üéØ 3. ÎπàÎèÑ ÎÜíÏùÄ Ïû•Î•¥ Ìè¨Ìï®Îêú ÏòÅÌôî Ïñ∏ÎçîÏÉòÌîåÎßÅ\n",
    "    high_freq_movies = pd.DataFrame()\n",
    "\n",
    "    for genre in high_freq_genres:\n",
    "        genre_data = non_rare_movies[non_rare_movies[\"genre_list\"].apply(lambda x: genre in x)]\n",
    "\n",
    "        # üö® ÏôÑÏ†Ñ Îã®ÎèÖ Ïû•Î•¥Îäî ÏÇ≠Ï†ú\n",
    "        genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
    "        only_high_freq_data = genre_data[genre_data[\"only_high_freq\"]]\n",
    "        mixed_genre_data = genre_data[~genre_data[\"only_high_freq\"]]\n",
    "\n",
    "        # üéØ 4. Îã®ÎèÖÏúºÎ°ú Ï°¥Ïû¨ÌïòÎäî ÎπàÎèÑ ÎÜíÏùÄ Ïû•Î•¥Îäî Í±∞Ïùò ÏÇ≠Ï†ú (90% Ïù¥ÏÉÅ Ï§ÑÏù¥Í∏∞)\n",
    "        max_keep = min(len(only_high_freq_data) // 10, 1000)  # ÏµúÎåÄ 1000Í∞úÎßå Ïú†ÏßÄ\n",
    "        sampled_only_high_freq = only_high_freq_data.sample(max_keep, random_state=42) if len(only_high_freq_data) > max_keep else only_high_freq_data\n",
    "\n",
    "        # üéØ 5. ÌòºÌï©Îêú Ïû•Î•¥Îäî Ï°∞Í∏àÎßå Ï§ÑÏù¥Í∏∞\n",
    "        max_mixed_keep = min(len(mixed_genre_data) // 2, 5000)  # ÏµúÎåÄ 5000Í∞ú Ïú†ÏßÄ\n",
    "        sampled_mixed = mixed_genre_data.sample(max_mixed_keep, random_state=42) if len(mixed_genre_data) > max_mixed_keep else mixed_genre_data\n",
    "\n",
    "        high_freq_movies = pd.concat([high_freq_movies, sampled_only_high_freq, sampled_mixed])\n",
    "\n",
    "    # üéØ 6. Ìù¨Í∑Ä Ïû•Î•¥ Ìè¨Ìï®Îêú ÏòÅÌôî + Ïñ∏ÎçîÏÉòÌîåÎßÅÌïú ÏòÅÌôî Í≤∞Ìï©\n",
    "    final_sampled_df = pd.concat([rare_movies, high_freq_movies])\n",
    "\n",
    "    return final_sampled_df.sample(frac=1, random_state=42).drop(columns=[\"has_rare\", \"only_high_freq\"])  # ÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ ÏÑûÍ∏∞\n",
    "\n",
    "\n",
    "# üöÄ Ïñ∏ÎçîÏÉòÌîåÎßÅ ÏàòÌñâ (Ìù¨Í∑Ä Ïû•Î•¥ Î≥¥Ìò∏ Ï†ÅÏö©)\n",
    "undersampled_df = final_balanced_under_sample(model_df, Counter(genre for genres in model_df[\"genre_list\"] for genre in genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132153           [History, Short, War]\n",
       "161722                 [Comedy, Sport]\n",
       "63680          [Crime, Drama, History]\n",
       "88499         [Biography, Documentary]\n",
       "13342     [Action, Adventure, Romance]\n",
       "                      ...             \n",
       "191867    [Documentary, Drama, Family]\n",
       "64035       [Action, Musical, Romance]\n",
       "29549         [Comedy, Music, Romance]\n",
       "24349      [Biography, Drama, Musical]\n",
       "145095                         [Adult]\n",
       "Name: genre_list, Length: 55064, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_df['genre_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49559"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(undersampled_df[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_counts = Counter(genre for genres in undersampled_df[\"genre_list\"] for genre in genres)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏúºÎ°ú Î≥ÄÌôò\n",
    "undersampled_genre_count_df = pd.DataFrame(genre_counts.items(), columns=[\"Genre\", \"Count\"]).sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drama</td>\n",
       "      <td>20785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>13994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short</td>\n",
       "      <td>9797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Action</td>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crime</td>\n",
       "      <td>7981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>6764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Romance</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animation</td>\n",
       "      <td>5052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adult</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Family</td>\n",
       "      <td>4132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Biography</td>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Horror</td>\n",
       "      <td>2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Music</td>\n",
       "      <td>2662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sport</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>War</td>\n",
       "      <td>2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Musical</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Western</td>\n",
       "      <td>2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Game-Show</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>News</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre  Count\n",
       "6         Drama  20785\n",
       "3        Comedy  13994\n",
       "1         Short   9797\n",
       "9        Action   9129\n",
       "5         Crime   7981\n",
       "10    Adventure   6764\n",
       "11      Romance   6563\n",
       "8   Documentary   5137\n",
       "14    Animation   5052\n",
       "21       Sci-Fi   4666\n",
       "16        Adult   4470\n",
       "0       History   4335\n",
       "13       Family   4132\n",
       "18     Thriller   4102\n",
       "7     Biography   3662\n",
       "20      Mystery   3202\n",
       "23       Horror   2869\n",
       "17        Music   2662\n",
       "4         Sport   2585\n",
       "15      Fantasy   2517\n",
       "2           War   2427\n",
       "12      Musical   2153\n",
       "22      Western   2090\n",
       "26    Game-Show    920\n",
       "19    Film-Noir    868\n",
       "25    Talk-Show    630\n",
       "27         News    611\n",
       "24   Reality-TV    451"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_genre_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132153</th>\n",
       "      <td>Captain Molly, or the Battle of Monmouth</td>\n",
       "      <td>The country writhing under the yoke of British...</td>\n",
       "      <td>[History, Short, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161722</th>\n",
       "      <td>Mike Bassett: England Manager</td>\n",
       "      <td>Manager suffers heart attack. Unqualified repl...</td>\n",
       "      <td>[Comedy, Sport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63680</th>\n",
       "      <td>Angels of Iron</td>\n",
       "      <td>BERLIN, 1948. During the few days of the block...</td>\n",
       "      <td>[Crime, Drama, History]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88499</th>\n",
       "      <td>Family Values: An American Tragedy</td>\n",
       "      <td>Family Values: An American Tragedy tells the s...</td>\n",
       "      <td>[Biography, Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>A Regular Scout</td>\n",
       "      <td>Fred Blake sets out to avenge his mother who d...</td>\n",
       "      <td>[Action, Adventure, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191867</th>\n",
       "      <td>Silent Crisis: Diabetes Among Us</td>\n",
       "      <td>A one-hour documentary for the Discovery Healt...</td>\n",
       "      <td>[Documentary, Drama, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64035</th>\n",
       "      <td>Naseeb</td>\n",
       "      <td>A lottery ticket changes the lives of four fri...</td>\n",
       "      <td>[Action, Musical, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29549</th>\n",
       "      <td>Cinderella Jones</td>\n",
       "      <td>Judy Jones, sings with a band and also works a...</td>\n",
       "      <td>[Comedy, Music, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>The Story of Vernon and Irene Castle</td>\n",
       "      <td>The story of the dancing team who taught the w...</td>\n",
       "      <td>[Biography, Drama, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145095</th>\n",
       "      <td>The Backroom</td>\n",
       "      <td>Master Ken presides over San Francisco's infam...</td>\n",
       "      <td>[Adult]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55064 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "132153  Captain Molly, or the Battle of Monmouth   \n",
       "161722             Mike Bassett: England Manager   \n",
       "63680                             Angels of Iron   \n",
       "88499         Family Values: An American Tragedy   \n",
       "13342                            A Regular Scout   \n",
       "...                                          ...   \n",
       "191867          Silent Crisis: Diabetes Among Us   \n",
       "64035                                     Naseeb   \n",
       "29549                           Cinderella Jones   \n",
       "24349       The Story of Vernon and Irene Castle   \n",
       "145095                              The Backroom   \n",
       "\n",
       "                                                     desc  \\\n",
       "132153  The country writhing under the yoke of British...   \n",
       "161722  Manager suffers heart attack. Unqualified repl...   \n",
       "63680   BERLIN, 1948. During the few days of the block...   \n",
       "88499   Family Values: An American Tragedy tells the s...   \n",
       "13342   Fred Blake sets out to avenge his mother who d...   \n",
       "...                                                   ...   \n",
       "191867  A one-hour documentary for the Discovery Healt...   \n",
       "64035   A lottery ticket changes the lives of four fri...   \n",
       "29549   Judy Jones, sings with a band and also works a...   \n",
       "24349   The story of the dancing team who taught the w...   \n",
       "145095  Master Ken presides over San Francisco's infam...   \n",
       "\n",
       "                          genre_list  \n",
       "132153         [History, Short, War]  \n",
       "161722               [Comedy, Sport]  \n",
       "63680        [Crime, Drama, History]  \n",
       "88499       [Biography, Documentary]  \n",
       "13342   [Action, Adventure, Romance]  \n",
       "...                              ...  \n",
       "191867  [Documentary, Drama, Family]  \n",
       "64035     [Action, Musical, Romance]  \n",
       "29549       [Comedy, Music, Romance]  \n",
       "24349    [Biography, Drama, Musical]  \n",
       "145095                       [Adult]  \n",
       "\n",
       "[55064 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Î™®Îç∏ Î°úÎìú (8-bit Ï†ÅÏö©)\n",
    "MODEL_NAME = \"unsloth/phi-4-unsloth-bnb-4bit\"\n",
    "load_in_4bit = True\n",
    "max_seq_length = 1024\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = MODEL_NAME,\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     load_in_4bit = load_in_4bit,\n",
    "#     # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.2.15 patched 40 layers with 40 QKV layers, 40 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 21,299,200 || all params: 14,680,806,400 || trainable%: 0.1451\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], # self-attention Î†àÏù¥Ïñ¥\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.print_trainable_parameters()  # ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îßå ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"üö® Warning: NaN detected in {name} parameter!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Î™®Îì† LoRA ÌååÎùºÎØ∏ÌÑ∞Î•º Î™®Îç∏Ïùò dtypeÍ≥º ÎèôÏùºÌïòÍ≤å Î≥ÄÌôò\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" in name:  # üî• LoRA ÌååÎùºÎØ∏ÌÑ∞Îßå Î≥ÄÌôò\n",
    "        param.data = param.data.to(model.dtype)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" in name:\n",
    "        print(name, param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 21299200\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_filtered_negative_samples(genre_list, all_genres, num_neg_samples=3):\n",
    "    \n",
    "    negative_candidates = list(set(all_genres) - set(genre_list))\n",
    "\n",
    "    hard_neg_candidates = []\n",
    "    for genre in genre_list:\n",
    "        if genre in hard_negatives:\n",
    "            hard_neg_candidates.extend(hard_negatives[genre])\n",
    "\n",
    "    # Hard Negative ÌõÑÎ≥¥ Ï§ëÏóêÏÑú Ïã§Ï†ú Negative ÌõÑÎ≥¥ÏôÄ Í≤πÏπòÎäî Í≤ÉÎßå ÏÑ†ÌÉù\n",
    "    hard_neg_candidates = list(set(hard_neg_candidates) & set(negative_candidates))\n",
    "\n",
    "    # ÏµúÏ¢Ö Negative ÏÉòÌîåÎßÅ (Hard Negative + Ï∂îÍ∞Ä Negative)\n",
    "    if len(hard_neg_candidates) < num_neg_samples:\n",
    "        # Hard NegativeÍ∞Ä Î∂ÄÏ°±ÌïòÎ©¥ ÏùºÎ∞ò NegativeÏóêÏÑú Ï∂îÍ∞Ä\n",
    "        additional_negatives = list(set(negative_candidates) - set(hard_neg_candidates))\n",
    "        sampled_additional_negatives = random.sample(additional_negatives, num_neg_samples - len(hard_neg_candidates))\n",
    "        final_neg_samples = hard_neg_candidates + sampled_additional_negatives\n",
    "    else:\n",
    "        # Hard NegativeÍ∞Ä Ï∂©Î∂ÑÌïòÎ©¥ Í±∞Í∏∞ÏÑúÎßå ÏÉòÌîåÎßÅ\n",
    "        final_neg_samples = random.sample(hard_neg_candidates, num_neg_samples)\n",
    "\n",
    "    # Ïû•Î•¥ ÏÑ§Î™Ö ÌÖçÏä§Ìä∏ Î≥ÄÌôò\n",
    "    neg_texts = [label_descriptions[neg] for neg in final_neg_samples]\n",
    "\n",
    "    return neg_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>has_rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Three men hammer on an anvil and pass a bottle...</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Lost 1892 French short animated film directed ...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Lost short film consisting of 300 painted imag...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "      <td>[Animation, Comedy, Romance]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Performing on what looks like a small wooden s...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>Frog and Toad Are Friends</td>\n",
       "      <td>Claymation version of Arnold Lobel's story of ...</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>From Ardoyne to the √Åras: Inside the McAleese ...</td>\n",
       "      <td>Documentary on the private and public life of ...</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>Frontstadt</td>\n",
       "      <td>A young filmmaker tries to gain a very persona...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>Possible Changes</td>\n",
       "      <td>Two friends, Moon-ho and Jong-kyu, in their mi...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>Full Grown Men</td>\n",
       "      <td>A man stuck in the reveries of his youth track...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0                                        Blacksmith Scene   \n",
       "1                                             Un bon bock   \n",
       "2                                  Le clown et ses chiens   \n",
       "3                                            Poor Pierrot   \n",
       "4                                              Carmencita   \n",
       "...                                                   ...   \n",
       "207356                          Frog and Toad Are Friends   \n",
       "207357  From Ardoyne to the √Åras: Inside the McAleese ...   \n",
       "207358                                         Frontstadt   \n",
       "207359                                   Possible Changes   \n",
       "207360                                     Full Grown Men   \n",
       "\n",
       "                                                     desc  \\\n",
       "0       Three men hammer on an anvil and pass a bottle...   \n",
       "1       Lost 1892 French short animated film directed ...   \n",
       "2       Lost short film consisting of 300 painted imag...   \n",
       "3       One night, Arlequin come to see his lover Colo...   \n",
       "4       Performing on what looks like a small wooden s...   \n",
       "...                                                   ...   \n",
       "207356  Claymation version of Arnold Lobel's story of ...   \n",
       "207357  Documentary on the private and public life of ...   \n",
       "207358  A young filmmaker tries to gain a very persona...   \n",
       "207359  Two friends, Moon-ho and Jong-kyu, in their mi...   \n",
       "207360  A man stuck in the reveries of his youth track...   \n",
       "\n",
       "                          genre_list  has_rare  \n",
       "0                            [Short]     False  \n",
       "1                 [Animation, Short]     False  \n",
       "2                 [Animation, Short]     False  \n",
       "3       [Animation, Comedy, Romance]     False  \n",
       "4               [Documentary, Short]     False  \n",
       "...                              ...       ...  \n",
       "207356   [Animation, Comedy, Family]     False  \n",
       "207357                 [Documentary]     False  \n",
       "207358                       [Drama]     False  \n",
       "207359                       [Drama]     False  \n",
       "207360               [Comedy, Drama]     False  \n",
       "\n",
       "[207361 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, all_genres=None, max_length=128, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.all_genres = all_genres\n",
    "        self.max_length = max_length\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        title = row[\"title\"]\n",
    "        description = row[\"desc\"]\n",
    "        genre_list = row[\"genre_list\"]\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "\n",
    "            neg_texts = get_filtered_negative_samples(genre_list, all_genres)\n",
    "\n",
    "            story_prompt = f\"Movie Title: {title}, Story: {description}\"\n",
    "            label_prompt_pos = [\"Label: \" + label_descriptions[pos] for pos in genre_list]\n",
    "            label_prompt_neg = [\"Label: \" + neg for neg in neg_texts]  # Ïó¨Îü¨ Í∞úÏùò Negative ÏÉòÌîå\n",
    "\n",
    "            text_enc = self.tokenizer(story_prompt, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "            pos_enc = self.tokenizer(label_prompt_pos, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "            neg_enc = self.tokenizer(label_prompt_neg, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "            return {\n",
    "                \"text_input_ids\": text_enc[\"input_ids\"].squeeze(0),\n",
    "                \"text_attention_mask\": text_enc[\"attention_mask\"].squeeze(0),\n",
    "                \"positive_input_ids\": pos_enc[\"input_ids\"],\n",
    "                \"positive_attention_mask\": pos_enc[\"attention_mask\"],\n",
    "                \"negative_input_ids\": neg_enc[\"input_ids\"],\n",
    "                \"negative_attention_mask\": neg_enc[\"attention_mask\"]\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            return {\n",
    "                \"title\": title,\n",
    "                \"description\": description,\n",
    "                \"answer\": genre_list\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(undersampled_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = ContrastiveDataset(train_df, tokenizer, all_genres=all_genres)\n",
    "val_dataset = ContrastiveDataset(val_df, tokenizer, all_genres=all_genres)\n",
    "test_dataset = ContrastiveDataset(val_df, tokenizer, mode=\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    \"\"\"Î∞∞Ïπò ÎÇ¥ `positive_input_ids`Ïùò ÌÅ¨Í∏∞Î•º ÎßûÏ∂îÎäî Ìï®Ïàò\"\"\"\n",
    "\n",
    "    text_input_ids = torch.stack([b[\"text_input_ids\"] for b in batch])\n",
    "    text_attention_mask = torch.stack([b[\"text_attention_mask\"] for b in batch])\n",
    "\n",
    "    # üîπ Positive ÏÉòÌîå Ìå®Îî© Ï†ÅÏö© (Í∞ÄÏû• ÌÅ∞ `num_positives` Í∏∞Ï§Ä)\n",
    "    max_pos_samples = max([b[\"positive_input_ids\"].shape[0] for b in batch])  # Î∞∞Ïπò ÎÇ¥ Í∞ÄÏû• Í∏¥ Í∏çÏ†ï ÏÉòÌîå Í∞úÏàò Ï∞æÍ∏∞\n",
    "    pos_input_ids = [torch.cat([b[\"positive_input_ids\"], torch.zeros(max_pos_samples - b[\"positive_input_ids\"].shape[0], b[\"positive_input_ids\"].shape[1])]) if b[\"positive_input_ids\"].shape[0] < max_pos_samples else b[\"positive_input_ids\"] for b in batch]\n",
    "    pos_attention_mask = [torch.cat([b[\"positive_attention_mask\"], torch.zeros(max_pos_samples - b[\"positive_attention_mask\"].shape[0], b[\"positive_attention_mask\"].shape[1])]) if b[\"positive_attention_mask\"].shape[0] < max_pos_samples else b[\"positive_attention_mask\"] for b in batch]\n",
    "\n",
    "    pos_input_ids = torch.stack(pos_input_ids)\n",
    "    pos_attention_mask = torch.stack(pos_attention_mask)\n",
    "\n",
    "    # üîπ Negative ÏÉòÌîå (3Í∞úÎ°ú Í≥†Ï†ï)\n",
    "    neg_input_ids = torch.stack([b[\"negative_input_ids\"] for b in batch])\n",
    "    neg_attention_mask = torch.stack([b[\"negative_attention_mask\"] for b in batch])\n",
    "\n",
    "    return {\n",
    "        \"text_input_ids\": text_input_ids,\n",
    "        \"text_attention_mask\": text_attention_mask,\n",
    "        \"positive_input_ids\": pos_input_ids.to(torch.long),\n",
    "        \"positive_attention_mask\": pos_attention_mask,\n",
    "        \"negative_input_ids\": neg_input_ids.to(torch.long),\n",
    "        \"negative_attention_mask\": neg_attention_mask\n",
    "    }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Test Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Î∞∞Ïπò ÌÅ¨Í∏∞ Î∂àÏùºÏπò Î¨∏Ï†ú Ìï¥Í≤∞\n",
    "    - `title`, `description`, `answer`Î•º Î¶¨Ïä§Ìä∏Î°ú Ïú†ÏßÄÌïòÏó¨ DataLoaderÍ∞Ä Ï≤òÎ¶¨ Í∞ÄÎä•ÌïòÎèÑÎ°ù Ìï®\n",
    "    \"\"\"\n",
    "    titles = [item[\"title\"] for item in batch]\n",
    "    descriptions = [item[\"description\"] for item in batch]\n",
    "    answers = [item[\"answer\"] for item in batch]  # Î¶¨Ïä§Ìä∏ ÌòïÌÉú Ïú†ÏßÄ\n",
    "\n",
    "    return {\n",
    "        \"title\": titles,\n",
    "        \"description\": descriptions,\n",
    "        \"answer\": answers\n",
    "    }\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=train_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=train_collate_fn)  # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Îäî shuffle X\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m      2\u001b[0m dtype\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "dtype = model.dtype\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def info_nce_loss(query, positives, negatives, temperature=0.1, eps=1e-12):\n",
    "    \"\"\"\n",
    "    - Contrastive InfoNCE loss with multiple positive & negative samples\n",
    "    - Handles NaN/Inf issues using `clamp()` and `nan_to_num()`\n",
    "    \"\"\"\n",
    "    # üöÄ 1. Normalize embeddings\n",
    "    query = F.normalize(query, p=2, dim=-1, eps=eps)\n",
    "    positives = F.normalize(positives, p=2, dim=-1, eps=eps)\n",
    "    negatives = F.normalize(negatives, p=2, dim=-1, eps=eps)\n",
    "\n",
    "    # üöÄ 2. Compute similarity scores (`clamp()` Î≤îÏúÑ ÏàòÏ†ï)\n",
    "    pos_sim = torch.exp(torch.clamp(torch.matmul(query.unsqueeze(1), positives.permute(0, 2, 1)).squeeze(1) / temperature, -20, 20))\n",
    "    neg_sim = torch.exp(torch.clamp(torch.matmul(query.unsqueeze(1), negatives.permute(0, 2, 1)).squeeze(1) / temperature, -20, 20))\n",
    "\n",
    "    # üöÄ 3. Compute denominator\n",
    "    pos_sim_sum = torch.sum(pos_sim, dim=-1)  # (batch_size)\n",
    "    neg_sim_sum = torch.sum(neg_sim, dim=-1)  # (batch_size)\n",
    "    denominator = pos_sim_sum + neg_sim_sum + eps  # üöÄ eps Ï§ÑÏûÑ\n",
    "\n",
    "    # üöÄ 4. Compute loss\n",
    "    loss = -torch.log(pos_sim_sum / denominator)\n",
    "\n",
    "    # üöÄ 5. Handle NaN values\n",
    "    loss = torch.nan_to_num(loss, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "\n",
    "    # üö® Debugging print (ÏµúÏ¥à Î™á Í∞úÎßå Ï∂úÎ†•)\n",
    "    if torch.isnan(loss).any() or loss.mean().item() == 0:\n",
    "        print(\"üö® Warning: Loss is NaN or 0!\")\n",
    "        print(f\"pos_sim: {pos_sim[:3]}\")\n",
    "        print(f\"neg_sim: {neg_sim[:3]}\")\n",
    "        print(f\"denominator: {denominator[:3]}\")\n",
    "        print(f\"loss: {loss[:3]}\")\n",
    "\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_group in optimizer.param_groups:\n",
    "#     param_group['params'] = [p.to(model.dtype) for p in param_group['params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group['params']:\n",
    "        print(f\"Optimizer Param dtype: {param.dtype}, Model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.dtype}, requires_grad={param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# üöÄ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•/Î∂àÎü¨Ïò§Í∏∞ ÏÑ§Ï†ï\n",
    "CHECKPOINT_PATH = \"model_checkpoint.pth\"\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, avg_train_loss, avg_val_loss, best_val_loss):\n",
    "    \"\"\" ÌïôÏäµ Ï§ëÍ∞ÑÏóê Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• \"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "    print(f\"‚úÖ Checkpoint saved at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer):\n",
    "    \"\"\" Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∂àÎü¨Ïò§Í∏∞ (ÏûàÏùÑ Í≤ΩÏö∞) \"\"\"\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1  # Îã§Ïùå ÏóêÌè¨ÌÅ¨Î∂ÄÌÑ∞ ÌïôÏäµ ÏãúÏûë\n",
    "        best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "        print(f\"üîÑ Resuming from checkpoint at epoch {start_epoch}\")\n",
    "        return start_epoch, best_val_loss\n",
    "    return 0, float(\"inf\")  # Ï≤òÏùåÎ∂ÄÌÑ∞ ÌïôÏäµ ÏãúÏûë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Í≤ÄÏ¶ù(Validation) Ìï®Ïàò Ï†ïÏùò\n",
    "def validation_step(model, val_dataloader):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validating\", leave=False):\n",
    "            query_emb = model(batch[\"text_input_ids\"], batch[\"text_attention_mask\"]).last_hidden_state[:, 0]\n",
    "\n",
    "            batch_size, num_positives, seq_len = batch[\"positive_input_ids\"].shape  \n",
    "            pos_input_ids = batch[\"positive_input_ids\"].reshape(batch_size * num_positives, seq_len)\n",
    "            pos_attention_mask = batch[\"positive_attention_mask\"].reshape(batch_size * num_positives, seq_len)\n",
    "\n",
    "            pos_output = model(input_ids=pos_input_ids, attention_mask=pos_attention_mask, output_hidden_states=True)\n",
    "            pos_emb = pos_output.hidden_states[-1][:, 0].reshape(batch_size, num_positives, -1)\n",
    "\n",
    "            batch_size, num_negatives, seq_len = batch[\"negative_input_ids\"].shape\n",
    "            neg_input_ids = batch[\"negative_input_ids\"].reshape(batch_size * num_negatives, seq_len)\n",
    "            neg_attention_mask = batch[\"negative_attention_mask\"].reshape(batch_size * num_negatives, seq_len)\n",
    "\n",
    "            neg_output = model(input_ids=neg_input_ids, attention_mask=neg_attention_mask, output_hidden_states=True)\n",
    "            neg_emb = neg_output.hidden_states[-1][:, 0].reshape(batch_size, num_negatives, -1)\n",
    "\n",
    "            # InfoNCE ÏÜêÏã§ Í≥ÑÏÇ∞\n",
    "            loss = info_nce_loss(query_emb, pos_emb, neg_emb)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    wandb.log({\"Val Loss\": avg_val_loss})\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"üö® Warning: NaN detected in {name} parameter!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11013"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/11013 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/11013 [00:01<?, ?it/s]\n",
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1891: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  start = re.search('logger\\.info\\([\\\"\\'].+?Running training', inner_training_loop).span(0)[0]\n",
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1894: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  spaces = re.search('\\n([\\s\\t]{1,})', original_debug).group(0)[1:]\n",
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1895: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  front_spaces = re.match('([\\s\\t]{1,})', inner_training_loop).group(0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# üî• Query ÏûÑÎ≤†Îî© Ï∂îÏ∂ú\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m query_emb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_input_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_attention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# üî• Positive Sample ÏûÑÎ≤†Îî©\u001b[39;00m\n\u001b[1;32m     33\u001b[0m batch_size, num_positives, seq_len \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape  \n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1216\u001b[0m, in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1215\u001b[0m ):\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1061\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_has_no_labels \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:853\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offloaded_gradient_checkpointing:\n\u001b[0;32m--> 853\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mUnsloth_Offloaded_Gradient_Checkpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m gradient_checkpointing:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_custom_forward\u001b[39m(module):\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/amp/autocast_mode.py:503\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth_zoo/gradient_checkpointing.py:147\u001b[0m, in \u001b[0;36mUnsloth_Offloaded_Gradient_Checkpointer.forward\u001b[0;34m(ctx, forward_function, hidden_states, *args)\u001b[0m\n\u001b[1;32m    145\u001b[0m saved_hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, non_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 147\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(saved_hidden_states)\n\u001b[1;32m    149\u001b[0m ctx\u001b[38;5;241m.\u001b[39mforward_function \u001b[38;5;241m=\u001b[39m forward_function\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:548\u001b[0m, in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    547\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm, hidden_states)\n\u001b[0;32m--> 548\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:242\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 242\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float"
     ]
    }
   ],
   "source": [
    "# üöÄ ÌïôÏäµ Î£®ÌîÑ (Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Í∏∞Îä• Ìè¨Ìï®)\n",
    "num_epochs = 3\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# üîÑ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ÏóêÏÑú Î∂àÎü¨Ïò§Í∏∞ (Ïù¥Ï†Ñ ÌïôÏäµ Ïû¨Í∞ú)\n",
    "start_epoch, best_val_loss = load_checkpoint(model, optimizer)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in train_bar:\n",
    "        for key, value in batch.items():\n",
    "            if torch.isnan(value).any():\n",
    "                print(f\"‚ùå NaN detected in batch[{key}]\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "\n",
    "        batch[\"text_input_ids\"] = batch[\"text_input_ids\"].to(device)\n",
    "        batch[\"text_attention_mask\"] = batch[\"text_attention_mask\"].to(device)\n",
    "        batch[\"positive_input_ids\"] = batch[\"positive_input_ids\"].to(device)\n",
    "        batch[\"positive_attention_mask\"] = batch[\"positive_attention_mask\"].to(device)\n",
    "        batch[\"negative_input_ids\"] = batch[\"negative_input_ids\"].to(device)\n",
    "        batch[\"negative_attention_mask\"] = batch[\"negative_attention_mask\"].to(device)\n",
    "\n",
    "        # üî• Query ÏûÑÎ≤†Îî© Ï∂îÏ∂ú\n",
    "        query_emb = model(batch[\"text_input_ids\"], batch[\"text_attention_mask\"], output_hidden_states=True).hidden_states[-1][:, 0]\n",
    "\n",
    "        # üî• Positive Sample ÏûÑÎ≤†Îî©\n",
    "        batch_size, num_positives, seq_len = batch[\"positive_input_ids\"].shape  \n",
    "        pos_input_ids = batch[\"positive_input_ids\"].view(batch_size * num_positives, seq_len)\n",
    "        pos_attention_mask = batch[\"positive_attention_mask\"].view(batch_size * num_positives, seq_len)\n",
    "        pos_output = model(input_ids=pos_input_ids, attention_mask=pos_attention_mask, output_hidden_states=True)\n",
    "        pos_emb = pos_output.hidden_states[-1][:, 0].view(batch_size, num_positives, -1)  # ÏõêÎûò Î∞∞Ïπò ÌòïÌÉúÎ°ú Î≥µÍµ¨\n",
    "\n",
    "        # üî• Negative Sample ÏûÑÎ≤†Îî©\n",
    "        batch_size, num_negatives, seq_len = batch[\"negative_input_ids\"].shape\n",
    "        neg_input_ids = batch[\"negative_input_ids\"].view(batch_size * num_negatives, seq_len)\n",
    "        neg_attention_mask = batch[\"negative_attention_mask\"].view(batch_size * num_negatives, seq_len)\n",
    "        neg_output = model(input_ids=neg_input_ids, attention_mask=neg_attention_mask, output_hidden_states=True)\n",
    "        neg_emb = neg_output.hidden_states[-1][:, 0].view(batch_size, num_negatives, -1)\n",
    "\n",
    "        # # ‚úÖ Í∞íÏù¥ ÎÑàÎ¨¥ ÌÅ¨Í±∞ÎÇò ÏûëÏïÑÏßÄÎäî Í≤É Î∞©ÏßÄ\n",
    "        # query_emb = query_emb.clone().clamp(-1e6, 1e6)\n",
    "        # pos_emb = pos_emb.clone().clamp(-1e6, 1e6)\n",
    "        # neg_emb = neg_emb.clone().clamp(-1e6, 1e6)\n",
    "\n",
    "\n",
    "        # üî• InfoNCE ÏÜêÏã§ Í≥ÑÏÇ∞\n",
    "        loss = info_nce_loss(query_emb, pos_emb, neg_emb)\n",
    "        if torch.isnan(loss).any():\n",
    "            print(\"‚ùå Loss contains NaN values!\")\n",
    "            exit()\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if torch.isnan(param).any():\n",
    "                print(f\"‚ùå NaN detected in model parameter: {name}\")\n",
    "\n",
    "\n",
    "        # üöÄ **GradScaler Ï†úÍ±∞ ÌõÑ ÏßÅÏ†ë backward() Ï†ÅÏö©**\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)]\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None and torch.isnan(param.grad).any():\n",
    "                print(f\"‚ùå NaN detected in gradients of {name}\")\n",
    "                exit()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    avg_val_loss = validation_step(model, val_dataloader)  # üöÄ ValidationÏóêÎèÑ AMP Ï†ÅÏö© ÌïÑÏöî\n",
    "\n",
    "    wandb.log({\"Train Loss\": avg_train_loss, \"Val Loss\": avg_val_loss})\n",
    "    print(f\"‚úÖ Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "    # üöÄ **Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•**\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        save_checkpoint(epoch, model, optimizer, avg_train_loss, avg_val_loss, best_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# üöÄ Ï†ÄÏû•Ìï† ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
    "save_directory = \"fine_tuned_phi4_lora\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# ‚úÖ LoRA Adapter Ï†ÄÏû•\n",
    "model.save_pretrained(save_directory)  # LoRA Adapter Ï†ÄÏû•\n",
    "tokenizer.save_pretrained(save_directory)  # ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Ï†ÄÏû•\n",
    "\n",
    "print(f\"‚úÖ Model and LoRA adapter saved at {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.69s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# üîπ Hugging Face Text Generation Pipeline ÏÑ§Ï†ï\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"unsloth/phi-4-unsloth-bnb-4bit\",\n",
    "    model_kwargs={\"torch_dtype\": \"auto\"},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2754"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132153</th>\n",
       "      <td>Captain Molly, or the Battle of Monmouth</td>\n",
       "      <td>The country writhing under the yoke of British...</td>\n",
       "      <td>[History, Short, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161722</th>\n",
       "      <td>Mike Bassett: England Manager</td>\n",
       "      <td>Manager suffers heart attack. Unqualified repl...</td>\n",
       "      <td>[Comedy, Sport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63680</th>\n",
       "      <td>Angels of Iron</td>\n",
       "      <td>BERLIN, 1948. During the few days of the block...</td>\n",
       "      <td>[Crime, Drama, History]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88499</th>\n",
       "      <td>Family Values: An American Tragedy</td>\n",
       "      <td>Family Values: An American Tragedy tells the s...</td>\n",
       "      <td>[Biography, Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>A Regular Scout</td>\n",
       "      <td>Fred Blake sets out to avenge his mother who d...</td>\n",
       "      <td>[Action, Adventure, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191867</th>\n",
       "      <td>Silent Crisis: Diabetes Among Us</td>\n",
       "      <td>A one-hour documentary for the Discovery Healt...</td>\n",
       "      <td>[Documentary, Drama, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64035</th>\n",
       "      <td>Naseeb</td>\n",
       "      <td>A lottery ticket changes the lives of four fri...</td>\n",
       "      <td>[Action, Musical, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29549</th>\n",
       "      <td>Cinderella Jones</td>\n",
       "      <td>Judy Jones, sings with a band and also works a...</td>\n",
       "      <td>[Comedy, Music, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>The Story of Vernon and Irene Castle</td>\n",
       "      <td>The story of the dancing team who taught the w...</td>\n",
       "      <td>[Biography, Drama, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145095</th>\n",
       "      <td>The Backroom</td>\n",
       "      <td>Master Ken presides over San Francisco's infam...</td>\n",
       "      <td>[Adult]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55064 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "132153  Captain Molly, or the Battle of Monmouth   \n",
       "161722             Mike Bassett: England Manager   \n",
       "63680                             Angels of Iron   \n",
       "88499         Family Values: An American Tragedy   \n",
       "13342                            A Regular Scout   \n",
       "...                                          ...   \n",
       "191867          Silent Crisis: Diabetes Among Us   \n",
       "64035                                     Naseeb   \n",
       "29549                           Cinderella Jones   \n",
       "24349       The Story of Vernon and Irene Castle   \n",
       "145095                              The Backroom   \n",
       "\n",
       "                                                     desc  \\\n",
       "132153  The country writhing under the yoke of British...   \n",
       "161722  Manager suffers heart attack. Unqualified repl...   \n",
       "63680   BERLIN, 1948. During the few days of the block...   \n",
       "88499   Family Values: An American Tragedy tells the s...   \n",
       "13342   Fred Blake sets out to avenge his mother who d...   \n",
       "...                                                   ...   \n",
       "191867  A one-hour documentary for the Discovery Healt...   \n",
       "64035   A lottery ticket changes the lives of four fri...   \n",
       "29549   Judy Jones, sings with a band and also works a...   \n",
       "24349   The story of the dancing team who taught the w...   \n",
       "145095  Master Ken presides over San Francisco's infam...   \n",
       "\n",
       "                          genre_list  \n",
       "132153         [History, Short, War]  \n",
       "161722               [Comedy, Sport]  \n",
       "63680        [Crime, Drama, History]  \n",
       "88499       [Biography, Documentary]  \n",
       "13342   [Action, Adventure, Romance]  \n",
       "...                              ...  \n",
       "191867  [Documentary, Drama, Family]  \n",
       "64035     [Action, Musical, Romance]  \n",
       "29549       [Comedy, Music, Romance]  \n",
       "24349    [Biography, Drama, Musical]  \n",
       "145095                       [Adult]  \n",
       "\n",
       "[55064 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the maximum number of genres assigned to a single movie\n",
    "max_genres_per_movie = undersampled_df[\"genre_list\"].apply(len).max()\n",
    "\n",
    "# Display the result\n",
    "max_genres_per_movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_llm_generation(test_dataloader, all_genres, output_file=\"llm_predictions.txt\"):\n",
    "    \"\"\"\n",
    "    - `unsloth/phi-4-unsloth-bnb-4bit` Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïû•Î•¥Î•º ÏòàÏ∏°ÌïòÍ≥† ÌèâÍ∞Ä\n",
    "    - `.txt` ÌååÏùºÏóê `[Prompt] [LLM Predictions] [Answer]` ÌòïÏãùÏúºÎ°ú Ï†ÄÏû•\n",
    "    - Precision, Recall, F1-score Í≥ÑÏÇ∞ ÌõÑ ÌååÏùºÏóê Ï∂îÍ∞Ä\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"LLM Movie Genre Prediction Results\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v for k, v in batch.items()}  # ÌÉÄÏù¥ÌãÄ, ÏÑ§Î™Ö, Ï†ïÎãµ Ìè¨Ìï®\n",
    "\n",
    "        # üöÄ ÌîÑÎ°¨ÌîÑÌä∏ Î©îÏãúÏßÄ ÏÉùÏÑ± (ÎåÄÌôîÌòï Î©îÏãúÏßÄ Ìè¨Îß∑ Ï†ÅÏö©)\n",
    "        prompts = [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are an AI movie genre classifier. Your task is to assign the most appropriate genres to a movie. Follow these rules: 1. Choose ONLY from the given genres: {', '.join(all_genres)}. 2.Assign the most relevant genres (1, 2, or 3) based on fit. If a movie strongly fits only one genre, assign just one. If two genres are a good fit, assign two. 3. Output ONLY the predicted genres as a comma-separated list. 4. Do NOT repeat or copy the full genre list. 5. Do NOT add explanations or extra text.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Movie Title: {title}, Story: {desc}, Predicted Genres:\"}\n",
    "            ]\n",
    "            for title, desc in zip(batch[\"title\"], batch[\"description\"])\n",
    "        ]\n",
    "        \n",
    "\n",
    "        # üöÄ Î™®Îç∏ ÏòàÏ∏° ÏàòÌñâ (Î∞∞Ïπò Îã®ÏúÑÎ°ú Ï≤òÎ¶¨)\n",
    "        outputs = [pipeline(prompt, max_new_tokens=15)[0][\"generated_text\"][-1] for prompt in prompts]\n",
    "\n",
    "        # üöÄ LLMÏù¥ ÏÉùÏÑ±Ìïú Ïû•Î•¥ ÌïÑÌÑ∞ÎßÅ (Ïò¨Î∞îÎ•∏ Ïû•Î•¥Îßå Ìè¨Ìï®)\n",
    "        filtered_preds = []\n",
    "        for pred in outputs:\n",
    "            pred_text = pred['content']\n",
    "            pred_lst = [genre.strip() for genre in pred_text.split(',')]\n",
    "            # pred_genres = [genre for genre in all_genres if genre in pred_lst]  # Ï†ïÌï¥ÏßÑ Ïû•Î•¥ Î™©Î°ùÏóê Ìè¨Ìï®Îêú Í≤ÉÎßå ÏÑ†ÌÉù\n",
    "            filtered_preds.append(pred_lst)\n",
    "\n",
    "        # üöÄ Ïã§Ï†ú Ï†ïÎãµ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        actual_labels = batch[\"answer\"]\n",
    "\n",
    "        # üöÄ ÌååÏùºÏóê Í∏∞Î°ù (ÏßÄÏ†ïÎêú ÌòïÏãù Ï†ÅÏö©)\n",
    "        with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            for prompt, pred, actual in zip(prompts, filtered_preds, actual_labels):\n",
    "                f.write(f\"[Prompt]\\n{prompt}\\n\\n\")\n",
    "                f.write(f\"[LLM Predictions]\\n{', '.join(pred)}\\n\\n\")\n",
    "                f.write(f\"[Answer]\\n{', '.join(actual)}\\n\")\n",
    "                f.write(\"-\" * 100 + \"\\n\\n\")\n",
    "\n",
    "        # üöÄ Î™®Îç∏Ïùò ÏòàÏ∏°Í∞íÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "        pred_vectors = [[1 if genre in pred else 0 for genre in all_genres] for pred in filtered_preds]\n",
    "        label_vectors = [[1 if genre in actual else 0 for genre in all_genres] for actual in actual_labels]\n",
    "\n",
    "        all_preds.extend(pred_vectors)\n",
    "        all_labels.extend(label_vectors)\n",
    "\n",
    "    # üöÄ Precision, Recall, F1-score Í≥ÑÏÇ∞\n",
    "    precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"LLM Generation - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    # üöÄ ÌèâÍ∞Ä Í≤∞Í≥º ÌååÏùºÏóê Ï†ÄÏû•\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "        f.write(f\"Final Evaluation Metrics:\\n\")\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        f.write(f\"F1-score: {f1:.4f}\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Generation - Precision: 0.5659, Recall: 0.6016, F1-score: 0.5488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5658517449133696, 0.6015991047924049, 0.5487915194729224)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_llm_generation(test_dataloader, all_genres)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecLLM",
   "language": "python",
   "name": "recllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
